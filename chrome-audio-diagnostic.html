<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üîç Chrome Audio Diagnostic - LISA TTS</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        .card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .test-row {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 10px 0;
            padding: 10px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }
        .status {
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: bold;
            min-width: 80px;
            text-align: center;
        }
        .pass { background: #4CAF50; }
        .fail { background: #f44336; }
        .warn { background: #ff9800; }
        .info { background: #2196F3; }
        button {
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        .diagnostic-log {
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            max-height: 300px;
            overflow-y: auto;
            margin-top: 15px;
        }
        .big-test-button {
            background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
            border: none;
            color: white;
            font-size: 18px;
            font-weight: bold;
            padding: 15px 30px;
            border-radius: 30px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
        }
        .big-test-button:hover {
            transform: scale(1.05);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        .voice-selector {
            margin: 10px 0;
            padding: 10px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
        }
        select {
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 8px;
            border-radius: 5px;
            width: 100%;
        }
        select option {
            background: #333;
            color: white;
        }
    </style>
</head>
<body>
    <h1>üîç Chrome Audio Diagnostic - LISA TTS</h1>
    <p>This tool will diagnose exactly why LISA's voice isn't working in Chrome.</p>

    <div class="card">
        <h2>üß™ Quick Diagnosis</h2>
        <button class="big-test-button" onclick="runFullDiagnostic()">Run Complete Audio Diagnostic</button>
        <button class="big-test-button" onclick="testLISAVoiceFlow()">Test LISA Voice Flow</button>
    </div>

    <div class="card">
        <h2>üìä Browser Capabilities</h2>
        <div id="browserTests"></div>
    </div>

    <div class="card">
        <h2>üé≠ Voice Selection</h2>
        <div class="voice-selector">
            <label>Available Voices:</label>
            <select id="voiceSelect" onchange="selectVoice()">
                <option value="">Select a voice...</option>
            </select>
        </div>
        <button onclick="testSelectedVoice()">Test Selected Voice</button>
    </div>

    <div class="card">
        <h2>üéöÔ∏è Audio Context Status</h2>
        <div id="audioContextTests"></div>
        <button onclick="testAudioContext()">Test Audio Context</button>
        <button onclick="resumeAudioContext()">Resume Audio Context</button>
    </div>

    <div class="card">
        <h2>üé§ Speech Synthesis Tests</h2>
        <div id="speechTests"></div>
        <button onclick="testBasicSpeech()">Test Basic Speech</button>
        <button onclick="testChromeCompliantSpeech()">Test Chrome-Compliant Speech</button>
        <button onclick="testLISAPhrase()">Test LISA Phrase</button>
    </div>

    <div class="card">
        <h2>üîå WebSocket Connection Test</h2>
        <div id="websocketTests"></div>
        <button onclick="testWebSocketConnection()">Test LISA Backend Connection</button>
        <button onclick="sendTestVoiceCommand()">Send Test Voice Command</button>
    </div>

    <div class="card">
        <h2>üìã Diagnostic Log</h2>
        <div class="diagnostic-log" id="diagnosticLog"></div>
        <button onclick="clearLog()">Clear Log</button>
        <button onclick="copyDiagnosticReport()">Copy Diagnostic Report</button>
    </div>

    <script src="/socket.io/socket.io.js"></script>
    <script>
        let selectedVoice = null;
        let audioContext = null;
        let socket = null;
        let testResults = [];

        function log(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const logElement = document.getElementById('diagnosticLog');
            const color = {
                'info': '#2196F3',
                'success': '#4CAF50',
                'error': '#f44336',
                'warn': '#ff9800'
            }[type] || '#2196F3';
            
            logElement.innerHTML += `<div style="color: ${color}">[${timestamp}] ${message}</div>`;
            logElement.scrollTop = logElement.scrollHeight;
            
            testResults.push({ timestamp, message, type });
        }

        function clearLog() {
            document.getElementById('diagnosticLog').innerHTML = '';
            testResults = [];
        }

        function addTestResult(container, test, status, details = '') {
            const row = document.createElement('div');
            row.className = 'test-row';
            
            const statusClass = {
                'PASS': 'pass',
                'FAIL': 'fail',
                'WARN': 'warn',
                'INFO': 'info'
            }[status] || 'info';
            
            row.innerHTML = `
                <span>${test}</span>
                <span class="status ${statusClass}">${status}</span>
            `;
            
            if (details) {
                row.innerHTML += `<div style="font-size: 12px; opacity: 0.8; margin-top: 5px;">${details}</div>`;
            }
            
            document.getElementById(container).appendChild(row);
        }

        async function runFullDiagnostic() {
            log('üîç Starting complete Chrome audio diagnostic...', 'info');
            clearTestResults();
            
            // Test browser capabilities
            testBrowserCapabilities();
            
            // Test audio context
            await testAudioContext();
            
            // Load and test voices
            await loadVoices();
            
            // Test speech synthesis
            await testSpeechSynthesis();
            
            // Test WebSocket connection
            await testWebSocketConnection();
            
            log('‚úÖ Diagnostic complete! Check results above.', 'success');
        }

        function clearTestResults() {
            ['browserTests', 'audioContextTests', 'speechTests', 'websocketTests'].forEach(id => {
                document.getElementById(id).innerHTML = '';
            });
        }

        function testBrowserCapabilities() {
            log('üåê Testing browser capabilities...', 'info');
            
            // Speech Synthesis
            const speechSupported = 'speechSynthesis' in window;
            addTestResult('browserTests', 'Speech Synthesis Support', speechSupported ? 'PASS' : 'FAIL');
            log(`Speech Synthesis: ${speechSupported ? '‚úÖ Supported' : '‚ùå Not supported'}`, speechSupported ? 'success' : 'error');
            
            // Audio Context
            const audioContextSupported = 'AudioContext' in window || 'webkitAudioContext' in window;
            addTestResult('browserTests', 'AudioContext Support', audioContextSupported ? 'PASS' : 'FAIL');
            log(`AudioContext: ${audioContextSupported ? '‚úÖ Supported' : '‚ùå Not supported'}`, audioContextSupported ? 'success' : 'error');
            
            // User Agent
            const isChrome = navigator.userAgent.includes('Chrome');
            addTestResult('browserTests', 'Chrome Browser', isChrome ? 'PASS' : 'WARN', navigator.userAgent);
            log(`Browser: ${navigator.userAgent}`, 'info');
            
            // HTTPS
            const isSecure = window.location.protocol === 'https:';
            addTestResult('browserTests', 'Secure Context (HTTPS)', isSecure ? 'PASS' : 'WARN', 
                          isSecure ? 'HTTPS - all audio features available' : 'HTTP - some features may be restricted');
            log(`Protocol: ${window.location.protocol} ${isSecure ? '(Secure)' : '(Insecure)'}`, isSecure ? 'success' : 'warn');
        }

        async function testAudioContext() {
            log('üéöÔ∏è Testing AudioContext...', 'info');
            
            try {
                // Create AudioContext
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContextClass();
                
                log(`AudioContext created with state: ${audioContext.state}`, 'info');
                addTestResult('audioContextTests', 'AudioContext Creation', 'PASS', `State: ${audioContext.state}`);
                
                // Test resuming if suspended
                if (audioContext.state === 'suspended') {
                    log('AudioContext suspended, attempting to resume...', 'warn');
                    await audioContext.resume();
                    log(`AudioContext resume result: ${audioContext.state}`, audioContext.state === 'running' ? 'success' : 'warn');
                    addTestResult('audioContextTests', 'AudioContext Resume', audioContext.state === 'running' ? 'PASS' : 'WARN', `Final state: ${audioContext.state}`);
                }
                
                return audioContext.state === 'running';
            } catch (error) {
                log(`‚ùå AudioContext error: ${error.message}`, 'error');
                addTestResult('audioContextTests', 'AudioContext Creation', 'FAIL', error.message);
                return false;
            }
        }

        async function resumeAudioContext() {
            if (audioContext && audioContext.state === 'suspended') {
                try {
                    await audioContext.resume();
                    log(`‚úÖ AudioContext resumed: ${audioContext.state}`, 'success');
                } catch (error) {
                    log(`‚ùå Failed to resume AudioContext: ${error.message}`, 'error');
                }
            } else {
                log('AudioContext is already running or not created', 'info');
            }
        }

        async function loadVoices() {
            log('üé≠ Loading voices...', 'info');
            
            return new Promise((resolve) => {
                const loadVoicesNow = () => {
                    const voices = speechSynthesis.getVoices();
                    log(`Found ${voices.length} voices`, 'info');
                    
                    const voiceSelect = document.getElementById('voiceSelect');
                    voiceSelect.innerHTML = '<option value="">Select a voice...</option>';
                    
                    voices.forEach((voice, index) => {
                        const option = document.createElement('option');
                        option.value = index;
                        option.textContent = `${voice.name} (${voice.lang}) ${voice.default ? '[Default]' : ''}`;
                        voiceSelect.appendChild(option);
                        
                        log(`Voice ${index}: ${voice.name} (${voice.lang}) ${voice.default ? '[Default]' : ''}`, 'info');
                    });
                    
                    addTestResult('speechTests', 'Voice Loading', voices.length > 0 ? 'PASS' : 'FAIL', `${voices.length} voices found`);
                    
                    // Auto-select a female English voice for LISA
                    const lisaVoice = voices.find(voice => 
                        voice.lang.startsWith('en') && (
                            voice.name.toLowerCase().includes('female') ||
                            voice.name.toLowerCase().includes('samantha') ||
                            voice.name.toLowerCase().includes('karen') ||
                            voice.name.toLowerCase().includes('moira')
                        )
                    ) || voices.find(voice => voice.lang.startsWith('en')) || voices[0];
                    
                    if (lisaVoice) {
                        const voiceIndex = voices.indexOf(lisaVoice);
                        voiceSelect.value = voiceIndex;
                        selectedVoice = lisaVoice;
                        log(`üé≠ Auto-selected LISA voice: ${lisaVoice.name}`, 'success');
                    }
                    
                    resolve();
                };
                
                if (speechSynthesis.getVoices().length > 0) {
                    loadVoicesNow();
                } else {
                    speechSynthesis.addEventListener('voiceschanged', loadVoicesNow, { once: true });
                    // Fallback timeout
                    setTimeout(() => {
                        if (speechSynthesis.getVoices().length === 0) {
                            log('‚ö†Ô∏è Voice loading timeout - continuing without voices', 'warn');
                            addTestResult('speechTests', 'Voice Loading', 'WARN', 'Timeout - no voices loaded');
                            resolve();
                        }
                    }, 3000);
                }
            });
        }

        function selectVoice() {
            const voiceSelect = document.getElementById('voiceSelect');
            const voiceIndex = parseInt(voiceSelect.value);
            
            if (!isNaN(voiceIndex)) {
                const voices = speechSynthesis.getVoices();
                selectedVoice = voices[voiceIndex];
                log(`‚úÖ Selected voice: ${selectedVoice.name}`, 'success');
            }
        }

        async function testSpeechSynthesis() {
            log('üé§ Testing speech synthesis...', 'info');
            
            // Test basic speech capability
            const basicTest = await testSpeechCapability('Basic speech test', 'Hello world');
            addTestResult('speechTests', 'Basic Speech', basicTest ? 'PASS' : 'FAIL');
            
            // Test with selected voice
            if (selectedVoice) {
                const voiceTest = await testSpeechCapability('Voice-specific test', 'Testing selected voice', selectedVoice);
                addTestResult('speechTests', 'Selected Voice Test', voiceTest ? 'PASS' : 'FAIL', selectedVoice.name);
            }
            
            // Test LISA phrase
            const lisaTest = await testSpeechCapability('LISA test', 'Hi, this is LISA, your Language Intelligence Support Assistant', selectedVoice);
            addTestResult('speechTests', 'LISA Phrase Test', lisaTest ? 'PASS' : 'FAIL');
        }

        function testSpeechCapability(testName, text, voice = null) {
            return new Promise((resolve) => {
                log(`üéµ ${testName}: "${text.substring(0, 30)}..."`, 'info');
                
                try {
                    // Cancel any ongoing speech
                    speechSynthesis.cancel();
                    
                    const utterance = new SpeechSynthesisUtterance(text);
                    if (voice) utterance.voice = voice;
                    utterance.rate = 0.9;
                    utterance.pitch = 1.0;
                    utterance.volume = 0.8;
                    
                    let resolved = false;
                    
                    utterance.onstart = () => {
                        if (!resolved) {
                            log(`‚úÖ ${testName} started successfully`, 'success');
                        }
                    };
                    
                    utterance.onend = () => {
                        if (!resolved) {
                            resolved = true;
                            log(`‚úÖ ${testName} completed successfully`, 'success');
                            resolve(true);
                        }
                    };
                    
                    utterance.onerror = (event) => {
                        if (!resolved) {
                            resolved = true;
                            log(`‚ùå ${testName} failed: ${event.error}`, 'error');
                            resolve(false);
                        }
                    };
                    
                    // Timeout
                    setTimeout(() => {
                        if (!resolved) {
                            resolved = true;
                            log(`‚è∞ ${testName} timeout`, 'warn');
                            speechSynthesis.cancel();
                            resolve(false);
                        }
                    }, 5000);
                    
                    speechSynthesis.speak(utterance);
                    
                } catch (error) {
                    log(`‚ùå ${testName} exception: ${error.message}`, 'error');
                    resolve(false);
                }
            });
        }

        function testBasicSpeech() {
            testSpeechCapability('Manual Basic Test', 'This is a basic speech test.').then(result => {
                log(`Basic speech test result: ${result ? 'PASS' : 'FAIL'}`, result ? 'success' : 'error');
            });
        }

        function testChromeCompliantSpeech() {
            // Test Chrome-compliant speech with user interaction
            log('üéØ Testing Chrome-compliant speech with user interaction...', 'info');
            
            // First resume audio context if needed
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    log('‚úÖ AudioContext resumed for Chrome test', 'success');
                    performChromeTest();
                });
            } else {
                performChromeTest();
            }
            
            function performChromeTest() {
                testSpeechCapability('Chrome Compliant Test', 'This is a Chrome-compliant speech test with user interaction.', selectedVoice).then(result => {
                    addTestResult('speechTests', 'Chrome Compliant Speech', result ? 'PASS' : 'FAIL');
                });
            }
        }

        function testSelectedVoice() {
            if (selectedVoice) {
                testSpeechCapability('Selected Voice Test', `Testing voice: ${selectedVoice.name}`, selectedVoice);
            } else {
                log('‚ùå No voice selected', 'error');
            }
        }

        function testLISAPhrase() {
            const lisaPhrase = "Hi, this is LISA, your Language Intelligence Support Assistant. I'm ready to help you with your glass manufacturing orders.";
            testSpeechCapability('LISA Introduction', lisaPhrase, selectedVoice).then(result => {
                log(`LISA phrase test result: ${result ? 'PASS' : 'FAIL'}`, result ? 'success' : 'error');
            });
        }

        async function testWebSocketConnection() {
            log('üîå Testing WebSocket connection to LISA backend...', 'info');
            
            return new Promise((resolve) => {
                try {
                    // Determine WebSocket URL
                    const wsUrl = window.location.hostname.includes('vercel.app') 
                        ? 'wss://orderoverview-dkro.onrender.com'
                        : 'ws://localhost:3001';
                    
                    log(`Connecting to: ${wsUrl}`, 'info');
                    
                    socket = io(wsUrl);
                    
                    const timeout = setTimeout(() => {
                        log('‚ùå WebSocket connection timeout', 'error');
                        addTestResult('websocketTests', 'WebSocket Connection', 'FAIL', 'Connection timeout');
                        resolve(false);
                    }, 10000);
                    
                    socket.on('connect', () => {
                        clearTimeout(timeout);
                        log('‚úÖ WebSocket connected successfully', 'success');
                        addTestResult('websocketTests', 'WebSocket Connection', 'PASS', wsUrl);
                    });
                    
                    socket.on('connected', (data) => {
                        log(`‚úÖ LISA session established: ${data.sessionId}`, 'success');
                        addTestResult('websocketTests', 'LISA Session', 'PASS', `Session: ${data.sessionId}`);
                        
                        if (data.message) {
                            log(`üì¢ LISA welcome: "${data.message}"`, 'info');
                            // Test speaking the welcome message
                            testSpeechCapability('LISA Welcome', data.message, selectedVoice);
                        }
                        
                        resolve(true);
                    });
                    
                    socket.on('connect_error', (error) => {
                        clearTimeout(timeout);
                        log(`‚ùå WebSocket connection error: ${error.message}`, 'error');
                        addTestResult('websocketTests', 'WebSocket Connection', 'FAIL', error.message);
                        resolve(false);
                    });
                    
                } catch (error) {
                    log(`‚ùå WebSocket test exception: ${error.message}`, 'error');
                    addTestResult('websocketTests', 'WebSocket Connection', 'FAIL', error.message);
                    resolve(false);
                }
            });
        }

        function sendTestVoiceCommand() {
            if (!socket || !socket.connected) {
                log('‚ùå Not connected to LISA backend', 'error');
                return;
            }
            
            log('üé§ Sending test voice command to LISA...', 'info');
            
            socket.emit('voice-command', {
                transcript: 'Hello LISA, this is a test of your speech capabilities',
                isEndOfSpeech: true,
                interimResults: false,
                useNaturalConversation: true
            });
            
            socket.once('voice-response', (data) => {
                log(`üì¢ LISA responded: "${data.response}"`, 'success');
                log(`Should speak: ${data.shouldSpeak}`, 'info');
                
                if (data.response && data.shouldSpeak) {
                    log('üîä Testing LISA response speech...', 'info');
                    testSpeechCapability('LISA Response', data.response, selectedVoice).then(result => {
                        addTestResult('websocketTests', 'LISA Voice Response', result ? 'PASS' : 'FAIL', data.response.substring(0, 50) + '...');
                    });
                } else {
                    log('‚ö†Ô∏è LISA response received but shouldSpeak is false', 'warn');
                    addTestResult('websocketTests', 'LISA Voice Response', 'WARN', 'Response received but shouldSpeak=false');
                }
            });
        }

        async function testLISAVoiceFlow() {
            log('üéØ Testing complete LISA voice flow...', 'info');
            
            // Step 1: Ensure audio context is ready
            await testAudioContext();
            
            // Step 2: Load voices
            await loadVoices();
            
            // Step 3: Connect to LISA
            const connected = await testWebSocketConnection();
            
            if (connected) {
                // Step 4: Send voice command and test response
                setTimeout(() => {
                    sendTestVoiceCommand();
                }, 2000);
            }
        }

        function copyDiagnosticReport() {
            const report = [
                'üîç LISA Chrome Audio Diagnostic Report',
                '=' * 50,
                `Timestamp: ${new Date().toISOString()}`,
                `User Agent: ${navigator.userAgent}`,
                `URL: ${window.location.href}`,
                `Protocol: ${window.location.protocol}`,
                '',
                'Test Results:',
                ...testResults.map(r => `[${r.timestamp}] ${r.type.toUpperCase()}: ${r.message}`)
            ].join('\n');
            
            navigator.clipboard.writeText(report).then(() => {
                log('üìã Diagnostic report copied to clipboard', 'success');
            }).catch(() => {
                log('‚ùå Failed to copy report to clipboard', 'error');
            });
        }

        // Initialize on page load
        window.addEventListener('load', () => {
            log('üöÄ Chrome Audio Diagnostic Tool initialized', 'info');
            log('Click "Run Complete Audio Diagnostic" to start testing', 'info');
        });
    </script>
</body>
</html>
